# safe-agent environment variables
# Copy this to .env and fill in your values

RUST_LOG=info

# Dashboard authentication (REQUIRED — agent will not start without these)
DASHBOARD_PASSWORD=changeme
JWT_SECRET=replace-with-a-long-random-string

# ── LLM Backend ──────────────────────────────────────────────────────────
# "claude" (default) — requires Claude Code CLI installed & authenticated
# "codex"            — requires OpenAI Codex CLI installed & authenticated
# "gemini"           — requires Google Gemini CLI installed & authenticated
# "aider"            — requires Aider installed; uses any provider via API keys
# "local"            — requires a GGUF model file + compiled with --features local
# LLM_BACKEND=claude

# ── Claude CLI settings (LLM_BACKEND=claude) ─────────────────────────────
# Path to the claude binary (default: "claude")
# CLAUDE_BIN=claude

# Claude Code config directory — selects which authenticated profile to use.
# e.g. /home/you/.claude-personal or /home/you/.claude-work
# CLAUDE_CONFIG_DIR=

# Model override: sonnet, opus, haiku
# CLAUDE_MODEL=sonnet

# ── Codex CLI settings (LLM_BACKEND=codex) ───────────────────────────────
# Path to the codex binary (default: "codex")
# CODEX_BIN=codex

# Model override: gpt-5-codex, o3, etc.
# CODEX_MODEL=

# Config profile from ~/.codex/config.toml
# CODEX_PROFILE=

# OpenAI API key (optional — codex can use saved ChatGPT auth instead)
# CODEX_API_KEY=

# ── Gemini CLI settings (LLM_BACKEND=gemini) ─────────────────────────────
# Path to the gemini binary (default: "gemini")
# GEMINI_BIN=gemini

# Model override: gemini-2.5-pro, gemini-2.5-flash, etc.
# GEMINI_MODEL=

# API key (optional — gemini CLI can use OAuth or AI Studio login)
# GEMINI_API_KEY=

# ── Aider settings (LLM_BACKEND=aider) ──────────────────────────────────
# Path to the aider binary (default: "aider")
# AIDER_BIN=aider

# Model string — any model aider supports, e.g. gpt-4o, claude-3.5-sonnet
# AIDER_MODEL=

# Aider uses standard provider keys from the environment:
#   OPENAI_API_KEY, ANTHROPIC_API_KEY, GEMINI_API_KEY, etc.

# ── Local GGUF settings (LLM_BACKEND=local) ──────────────────────────────
# Path to the .gguf model file (REQUIRED for local backend)
# MODEL_PATH=/path/to/model.gguf

# ── Tunnel (ngrok) ────────────────────────────────────────────────────────
# Setting NGROK_AUTHTOKEN automatically enables the tunnel even if
# tunnel.enabled = false in config.toml.
# NGROK_AUTHTOKEN=your-ngrok-authtoken

# Path to ngrok binary (default: "ngrok")
# NGROK_BIN=ngrok

# Override which local port to expose (default: dashboard port)
# NGROK_PORT=3030

# Use a static ngrok domain (free tier gets one)
# NGROK_DOMAIN=myapp.ngrok-free.app

# Telegram bot (optional)
# TELEGRAM_BOT_TOKEN=

# Note: Google OAuth credentials are managed per-skill via the dashboard
# credential UI.  Declare them in your skill's skill.toml under [[credentials]]
# and configure the values in the dashboard's Skills tab.
